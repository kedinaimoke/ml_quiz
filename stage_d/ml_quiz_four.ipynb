{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9fa52d7-9d02-4c4d-a7c4-c59c01fb0430",
   "metadata": {},
   "source": [
    "## Project Goal\n",
    "You will build artificial intelligence algorithms to label satellite image chips with different atmospheric conditions and the different classes of land cover/land use.  For this Multi-class Multi-Label problem, some of the labels are from the following categories: Cloud Cover (clear, partly, cloudy, haze), Primary RainForest, Water (rivers, lakes), Habitation (large city, small homes), Agriculture, Roads etc. The algorithms from this project will enable us to understand where, how and why deforestation happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c04389-6fe6-4f1f-bf5d-0febacce8109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries for loading and exploring the dataset.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_set = pd.read_csv(\"planet-understanding-the-amazon-from-space/train_v2.csv/train_v2.csv\")\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7babfb8-1b5b-4571-b983-77312b195ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_name    0\n",
       "tags          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if there are any missing tags\n",
    "\n",
    "train_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bbcad1d-3d10-49f0-8d8c-e004018c4fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clear', 'selective_logging', 'haze', 'cultivation', 'slash_burn', 'primary', 'blow_down', 'bare_ground', 'agriculture', 'habitation', 'partly_cloudy', 'artisinal_mine', 'road', 'water', 'blooming', 'cloudy', 'conventional_mine']\n"
     ]
    }
   ],
   "source": [
    "labels = set()\n",
    "\n",
    "def splitting_tags(tags):\n",
    "    \"\"\"\n",
    "    Takes in a column of tags, splits the tags, and stores unique labels in a set.\n",
    "\n",
    "    Parameters:\n",
    "    - tags (str): A string containing space-separated tags.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    [labels.add(tag) for tag in tags.split()]\n",
    "\n",
    "# Create a copy of train_label\n",
    "train_clone = train_set.copy()\n",
    "\n",
    "# Apply the splitting_tags function to the 'tags' column\n",
    "train_clone['tags'].apply(splitting_tags)\n",
    "\n",
    "# Convert the set of unique labels to a list\n",
    "labels = list(labels)\n",
    "\n",
    "# Get unique labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b141892-4da2-488b-8ce4-f2037b053c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>clear</th>\n",
       "      <th>selective_logging</th>\n",
       "      <th>haze</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>slash_burn</th>\n",
       "      <th>primary</th>\n",
       "      <th>blow_down</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>habitation</th>\n",
       "      <th>partly_cloudy</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>road</th>\n",
       "      <th>water</th>\n",
       "      <th>blooming</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>conventional_mine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>haze primary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1.jpg</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2.jpg</td>\n",
       "      <td>clear primary</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3.jpg</td>\n",
       "      <td>clear primary</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4.jpg</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_name                                       tags  clear  \\\n",
       "0  train_0.jpg                               haze primary      0   \n",
       "1  train_1.jpg            agriculture clear primary water      1   \n",
       "2  train_2.jpg                              clear primary      1   \n",
       "3  train_3.jpg                              clear primary      1   \n",
       "4  train_4.jpg  agriculture clear habitation primary road      1   \n",
       "\n",
       "   selective_logging  haze  cultivation  slash_burn  primary  blow_down  \\\n",
       "0                  0     1            0           0        1          0   \n",
       "1                  0     0            0           0        1          0   \n",
       "2                  0     0            0           0        1          0   \n",
       "3                  0     0            0           0        1          0   \n",
       "4                  0     0            0           0        1          0   \n",
       "\n",
       "   bare_ground  agriculture  habitation  partly_cloudy  artisinal_mine  road  \\\n",
       "0            0            0           0              0               0     0   \n",
       "1            0            1           0              0               0     0   \n",
       "2            0            0           0              0               0     0   \n",
       "3            0            0           0              0               0     0   \n",
       "4            0            1           1              0               0     1   \n",
       "\n",
       "   water  blooming  cloudy  conventional_mine  \n",
       "0      0         0       0                  0  \n",
       "1      1         0       0                  0  \n",
       "2      0         0       0                  0  \n",
       "3      0         0       0                  0  \n",
       "4      0         0       0                  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform one-hot encoding on the \"Unique\" labels in the specified cloned train df.\n",
    "for tag in labels:\n",
    "    train_clone[tag] = train_clone['tags'].apply(lambda x: 1 if tag in x.split() else 0)\n",
    "\n",
    "# Adding '.jpg' extension to the 'image_name' column for same file format\n",
    "train_clone['image_name'] = train_clone['image_name'].apply(lambda x: '{}.jpg'.format(x))\n",
    "\n",
    "train_clone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5801c684-6a2f-4db0-95aa-369d7b8208ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clear',\n",
       " 'selective_logging',\n",
       " 'haze',\n",
       " 'cultivation',\n",
       " 'slash_burn',\n",
       " 'primary',\n",
       " 'blow_down',\n",
       " 'bare_ground',\n",
       " 'agriculture',\n",
       " 'habitation',\n",
       " 'partly_cloudy',\n",
       " 'artisinal_mine',\n",
       " 'road',\n",
       " 'water',\n",
       " 'blooming',\n",
       " 'cloudy',\n",
       " 'conventional_mine']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get and assign definition to the columns that were newly added from encoding\n",
    "columns = list(train_clone.columns[2:])\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8726b9c-b927-49b5-a31e-bf8f0e53ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f2c6e79-3f1f-4fcd-a3d4-8ba68f320d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta(y_true, y_pred, beta=2, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    Calculate the F-beta score.\n",
    "\n",
    "    Args:\n",
    "        y_true (tf.Tensor): Correct target values.\n",
    "        y_pred (tf.Tensor): Predicted values returned by the classifier.\n",
    "        beta (float): Weight parameter for precision in the F-beta score (default is 2).\n",
    "        epsilon (float): Smoothing term to avoid division by zero (default is 1e-4).\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: F-beta score.\n",
    "    \"\"\"\n",
    "    beta_squared = beta**2\n",
    "\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n",
    "\n",
    "    tp = tf.reduce_sum(y_true * y_pred, axis=1)\n",
    "    fp = tf.reduce_sum(y_pred, axis=1) - tp\n",
    "    fn = tf.reduce_sum(y_true, axis=1) - tp\n",
    "\n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "\n",
    "    fb = (1 + beta_squared) * precision * recall / (beta_squared * precision + recall + epsilon)\n",
    "    return fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbcadf62-ee2d-4b58-9de8-0ecb81099f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_acc(y_true, y_pred, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    Returns accuracy value for multi-label classification.\n",
    "\n",
    "    Args:\n",
    "        y_true (tf.Tensor): Correct target values.\n",
    "        y_pred (tf.Tensor): Predicted values returned by the classifier.\n",
    "        epsilon (float): Smoothing term to avoid division by zero (default is 1e-4).\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Accuracy score.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n",
    "\n",
    "    tp = tf.reduce_sum(y_true * y_pred, axis=1)\n",
    "    fp = tf.reduce_sum(y_pred, axis=1) - tp\n",
    "    fn = tf.reduce_sum(y_true, axis=1) - tp\n",
    "\n",
    "    y_true = tf.cast(y_true, tf.bool)\n",
    "    y_pred = tf.cast(y_pred, tf.bool)\n",
    "\n",
    "    tn = tf.reduce_sum(tf.cast(tf.logical_not(y_true), tf.float32)\n",
    "                       * tf.cast(tf.logical_not(y_pred), tf.float32), axis=1)\n",
    "\n",
    "    return (tp + tn) / (tp + tn + fp + fn + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94573f54-d810-48b5-aace-5418959d5be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8b30a8-4d41-427a-9a8c-c2928ed6b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "    Build and compile a convolutional neural network model for multi-label image classification.\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.models.Sequential: The compiled model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(128, 128, 3)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "\n",
    "    #  binary_crossentropy is used here because categorical_crossentropy l1 norms the output before calculating loss.\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[multi_label_acc, fbeta])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8f625b2-1735-428e-9bcc-09295fcd873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09317d4e-4621-40b4-ac86-a2134983166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint method is set to monitor the model using validation fbeta score and save the best only\n",
    "save_best_checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.hdf5',\n",
    "    monitor='val_fbeta',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd490bac-a2a0-423a-be4e-83de87a16183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeb54517-f8c0-4fbb-a22a-cab6cb1beb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32384 validated image filenames.\n",
      "Found 8095 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Initializing ImageDataGenerator method with a validation split of 0.2\n",
    "train_image_gen = ImageDataGenerator(rescale=1/255, validation_split=0.2)\n",
    "\n",
    "# Generating train data generator (80%)\n",
    "train_generator = train_image_gen.flow_from_dataframe(\n",
    "    dataframe=train_clone,\n",
    "    directory=\"train-jpg.tar/train-jpg/train-jpg\",\n",
    "    x_col=\"image_name\", y_col=columns, subset=\"training\",\n",
    "    batch_size=16, seed=2021, shuffle=True,\n",
    "    class_mode=\"raw\", target_size=(128, 128)\n",
    ")\n",
    "\n",
    "# Generating validation data (20%)\n",
    "val_generator = train_image_gen.flow_from_dataframe(\n",
    "    dataframe=train_clone,\n",
    "    directory=\"train-jpg.tar/train-jpg/train-jpg\",\n",
    "    x_col=\"image_name\", y_col=columns, subset=\"validation\",\n",
    "    batch_size=16, seed=2021, shuffle=True,\n",
    "    class_mode=\"raw\", target_size=(128, 128)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da01ce2-35a0-44ed-b9d6-7a5bb13988e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (Batch  (None, 128, 128, 3)       12        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 126, 126, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 63, 63, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 63, 63, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 61, 61, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 6, 6, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4719104   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 17)                8721      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5900093 (22.51 MB)\n",
      "Trainable params: 5900087 (22.51 MB)\n",
      "Non-trainable params: 6 (24.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Setting train and test data\n",
    "step_train_size = int(np.ceil(train_generator.samples / train_generator.batch_size))\n",
    "step_val_size = int(np.ceil(val_generator.samples / val_generator.batch_size))\n",
    "\n",
    "# call the model\n",
    "image_model = build_model()\n",
    "\n",
    "# get over of model architecture\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e73f31e8-872a-49eb-ae26-2f17f35027a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2024/2024 [==============================] - 3201s 2s/step - loss: 0.1417 - multi_label_acc: 0.9445 - fbeta: 0.8206 - val_loss: 0.1341 - val_multi_label_acc: 0.9478 - val_fbeta: 0.8308\n",
      "Epoch 2/5\n",
      "2024/2024 [==============================] - 3326s 2s/step - loss: 0.1371 - multi_label_acc: 0.9461 - fbeta: 0.8280 - val_loss: 0.1283 - val_multi_label_acc: 0.9501 - val_fbeta: 0.8440\n",
      "Epoch 3/5\n",
      "2024/2024 [==============================] - 3363s 2s/step - loss: 0.1342 - multi_label_acc: 0.9472 - fbeta: 0.8327 - val_loss: 0.1271 - val_multi_label_acc: 0.9505 - val_fbeta: 0.8439\n",
      "Epoch 4/5\n",
      "2024/2024 [==============================] - 3162s 2s/step - loss: 0.1321 - multi_label_acc: 0.9481 - fbeta: 0.8369 - val_loss: 0.1243 - val_multi_label_acc: 0.9517 - val_fbeta: 0.8544\n",
      "Epoch 5/5\n",
      "2024/2024 [==============================] - 3716s 2s/step - loss: 0.1316 - multi_label_acc: 0.9484 - fbeta: 0.8368 - val_loss: 0.1258 - val_multi_label_acc: 0.9518 - val_fbeta: 0.8489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x255d5bc3f90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The image model is fitted on the pre-defined functions\n",
    "image_model.fit(x=train_generator, \n",
    "           steps_per_epoch=step_train_size, \n",
    "           validation_data=val_generator, \n",
    "           validation_steps=step_val_size,\n",
    "            epochs=5, \n",
    "           callbacks=[save_best_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d06738fc-0677-4382-a5b5-6ac937b12048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0.jpg</td>\n",
       "      <td>primary clear agriculture road water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1.jpg</td>\n",
       "      <td>primary clear agriculture road water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2.jpg</td>\n",
       "      <td>primary clear agriculture road water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3.jpg</td>\n",
       "      <td>primary clear agriculture road water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4.jpg</td>\n",
       "      <td>primary clear agriculture road water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_name                                  tags\n",
       "0  test_0.jpg  primary clear agriculture road water\n",
       "1  test_1.jpg  primary clear agriculture road water\n",
       "2  test_2.jpg  primary clear agriculture road water\n",
       "3  test_3.jpg  primary clear agriculture road water\n",
       "4  test_4.jpg  primary clear agriculture road water"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A second model is initialised for making predictions\n",
    "image_model2 = build_model()\n",
    "\n",
    "# The second model is then loaded with the weights of the trained model (best_model.hdf5)\n",
    "image_model2.load_weights('best_model.hdf5')\n",
    "\n",
    "# adding .jpg extension to all rows in the image name column in the sample submission file\n",
    "sample = pd.read_csv(\"planet-understanding-the-amazon-from-space/sample_submission_v2.csv/sample_submission_v2.csv\")\n",
    "sample_clone = sample.copy()\n",
    "sample_clone['image_name'] = sample_clone['image_name'].apply(lambda x: '{}.jpg'.format(x))\n",
    "sample_clone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d06e4af-bbf4-4d51-993c-a69fae72683d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_name\n",
       "0  test_0.jpg\n",
       "1  test_1.jpg\n",
       "2  test_2.jpg\n",
       "3  test_3.jpg\n",
       "4  test_4.jpg"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the sample submission file into two\n",
    "\n",
    "test_df = sample_clone.iloc[:40669]['image_name'].reset_index().drop('index', axis =1)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffeb8cf2-e0bd-405e-aa69-975e634c5b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40669 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Call ImageDataGenerator\n",
    "test_image_gen = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "# Generator is created for the images found in the first test image files\n",
    "test_generator = test_image_gen.flow_from_dataframe(dataframe=test_df, \n",
    "                                                directory=\"test-jpg/test-jpg\", \n",
    "                                                x_col=\"image_name\", \n",
    "                                                y_col=None, \n",
    "                                                batch_size=16, \n",
    "                                                shuffle=False, \n",
    "                                                class_mode=None, \n",
    "                                                target_size=(128,128))\n",
    "\n",
    "step_test_size = int(np.ceil(test_generator.samples/test_generator.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c01ec37e-41df-4674-8637-5034fa283789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2542/2542 [==============================] - 2700s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Generator is tested to avoid shuffling of index\n",
    "test_generator.reset()\n",
    "pred = image_model2.predict(test_generator, steps=step_test_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "265cc92e-b36c-4957-aef3-ff793ff897bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0.jpg</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1.jpg</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2.jpg</td>\n",
       "      <td>primary partly_cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3.jpg</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4.jpg</td>\n",
       "      <td>primary partly_cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_name                   tags\n",
       "0  test_0.jpg          clear primary\n",
       "1  test_1.jpg          clear primary\n",
       "2  test_2.jpg  primary partly_cloudy\n",
       "3  test_3.jpg          clear primary\n",
       "4  test_4.jpg  primary partly_cloudy"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get filenames in the generator using the attribute .filenames\n",
    "file_names = test_generator.filenames\n",
    "\n",
    "# Convert the predicted values into a Pandas DataFrame. Then, join the two labels together into a \n",
    "# single label if the probability of occurrence of either label is greater than 0.5. This will provide \n",
    "# a more concise and clear representation of the predicted labels.\n",
    "\n",
    "pred_tags = pd.DataFrame(pred)\n",
    "pred_tags = pred_tags.apply(lambda x: ' '.join(np.array(labels)[x > 0.5]), axis = 1)\n",
    "\n",
    "# Store result in a DataFrame\n",
    "result_df = pd.DataFrame({'image_name': file_names, 'tags': pred_tags})\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c67008d-a11c-4fce-92cb-2c6514eac7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file_10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file_100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file_1000.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_name\n",
       "0     file_0.jpg\n",
       "1     file_1.jpg\n",
       "2    file_10.jpg\n",
       "3   file_100.jpg\n",
       "4  file_1000.jpg"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another test is added ...\n",
    "test_df2 = sample_clone.iloc[40669:]['image_name'].reset_index().drop('index', axis =1)\n",
    "test_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df63cc5e-fc11-4c51-8e70-81da46d43fde",
   "metadata": {},
   "source": [
    "The same operations are done on the first test DataFrame carried out on the additional test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80a90fd3-f2c2-429f-9e89-427656763e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20522 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_df2_generator = test_image_gen.flow_from_dataframe(dataframe=test_df2, \n",
    "                                                    directory =\"test-jpg-additional.tar/test-jpg-additional/test-jpg-additional\", \n",
    "                                                    x_col=\"image_name\", \n",
    "                                                    y_col=None, \n",
    "                                                    batch_size=16, \n",
    "                                                    shuffle=False, \n",
    "                                                    class_mode=None, \n",
    "                                                    target_size=(128,128))\n",
    "\n",
    "\n",
    "step_test_size2 = int(np.ceil(test_df2_generator.samples/test_df2_generator.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f080eff-c1d5-44e8-8767-fa86ee2a378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1283/1283 [==============================] - 1433s 1s/step\n"
     ]
    }
   ],
   "source": [
    "test_df2_generator.reset()\n",
    "test_df2_pred = image_model2.predict(test_df2_generator, steps=step_test_size2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bff0a70b-86f5-48f4-a352-f95261f90ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file_0.jpg</td>\n",
       "      <td>clearprimary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file_1.jpg</td>\n",
       "      <td>clearprimaryagricultureroad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file_10.jpg</td>\n",
       "      <td>primaryagriculturewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file_100.jpg</td>\n",
       "      <td>clearprimaryagriculturewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file_1000.jpg</td>\n",
       "      <td>clearprimary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_name                          tags\n",
       "0     file_0.jpg                  clearprimary\n",
       "1     file_1.jpg   clearprimaryagricultureroad\n",
       "2    file_10.jpg       primaryagriculturewater\n",
       "3   file_100.jpg  clearprimaryagriculturewater\n",
       "4  file_1000.jpg                  clearprimary"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = test_df2_generator.filenames\n",
    "\n",
    "add_pred_tags = pd.DataFrame(test_df2_pred)\n",
    "add_pred_tags = add_pred_tags.apply(lambda x: ''.join(np.array(labels)[x > 0.5]), axis=1)\n",
    "\n",
    "result_df2 = pd.DataFrame({'image_name': file_names, 'tags': add_pred_tags})\n",
    "result_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23cd228c-ebef-4442-851f-289bb550376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61191, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0.jpg</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1.jpg</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2.jpg</td>\n",
       "      <td>primary partly_cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3.jpg</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4.jpg</td>\n",
       "      <td>primary partly_cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_name                   tags\n",
       "0  test_0.jpg          clear primary\n",
       "1  test_1.jpg          clear primary\n",
       "2  test_2.jpg  primary partly_cloudy\n",
       "3  test_3.jpg          clear primary\n",
       "4  test_4.jpg  primary partly_cloudy"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the 1st & 2nd results...\n",
    "final_df = pd.concat([result_df, result_df2])\n",
    "final_df = final_df.reset_index().drop('index', axis=1)\n",
    "\n",
    "# Get shape of final result\n",
    "print(final_df.shape)\n",
    "\n",
    "# Get overview of the final result\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29a919a9-2e42-4cb8-846a-c28b421ac3d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# .jpg extension is removed since all operations have been carried out\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m final_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_result\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m      3\u001b[0m final_result\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_result' is not defined"
     ]
    }
   ],
   "source": [
    "# .jpg extension is removed since all operations have been carried out\n",
    "final_df['image_name'] = final_r['image_name'].apply(lambda x: x[:-4])\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d697e116-3bd5-4453-9e0d-1c63842d72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.to_csv('image_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
